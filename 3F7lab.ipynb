{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3F7 Lab: CamZIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all functions from the package trees where we put together a number of tools for handling trees in the 3F7 lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from trees import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a simple tree (play around with this command and construct more complicated trees....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = [[-1, 0, 0, 1, 1, 3, 3, 4, 2],\n",
    "     [-1, 0, 0, 1, 1, 2, 2, 3, 3], \n",
    "     [0, -1, 0, 1, 1, 2, 2, 3, 3], \n",
    "     [-1, 0, 0, 0, 1, 3, 4, 4, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will print a string that can be copy-pasted into a tree visualising website like [phylo.io](https://phylo.io) (don't forget to add a new line at the end of the string after cutting and pasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options for Q1:\n",
      "(((1000,1001)1007,(1002)1008)1005,(1003)1006)1004\n",
      "(((1003,1004)1008,1000)1006,(1001,1002)1007)1005\n",
      "((1003,1004)1008,1000)1006\n",
      "(((1002,1003)1008)1006,1000,(1001,1004)1007)1005\n",
      "Cut and paste the string on the previous line and add a \"new line\" at the end of the string.\n"
     ]
    }
   ],
   "source": [
    "print(\"Options for Q1:\")\n",
    "for i in t:\n",
    "    print(tree2newick(i))\n",
    "print('Cut and paste the string on the previous line and add a \"new line\" at the end of the string.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add labels to the nodes in the `tree2newick` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((grandchild 0,grandchild 1)child 0,child 1)root\n"
     ]
    }
   ],
   "source": [
    "print(tree2newick(t,['root', 'child 0', 'grandchild 0', 'grandchild 1', 'child 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are less labels than nodes, the labels will be interpreted \"leaves first\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((symbol 0,symbol 1)1004,symbol 2)1003\n"
     ]
    }
   ],
   "source": [
    "print(tree2newick(t,['symbol 0','symbol 1', 'symbol 2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command converts a variable-length code described by a tree to a code table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1000': [0, 0], '1001': [0, 1], '1002': [1]}\n"
     ]
    }
   ],
   "source": [
    "print(tree2code(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the inverse function can recover the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(code2tree(tree2code(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the following may happen as well. Can you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(code2tree(tree2code([3,3,4,4,-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(child 0,(grandchild 0,grandchild 1)child 1)root\n"
     ]
    }
   ],
   "source": [
    "print(tree2newick([3,3,4,4,-1], ['grandchild 0', 'grandchild 1', 'child 0', 'child 1', 'root']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly but far more problematic is the following inversion. The resulting assignment of codeword to symbols is fundamentally different from the original and would result in wrong decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1000': [0], '1001': [1, 0], '1002': [1, 1, 0], '1003': [1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tree2code(code2tree({'0':[1], '1':[0,1], '2':[0,0,1], '3':[0,0,0]})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These problems are all solved when using the extended tree format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, [], 'a'], [3, [], 'b'], [4, [], 'c'], [4, [0, 1], '1003'], [-1, [2, 3], '1004']]\n"
     ]
    }
   ],
   "source": [
    "xt = tree2xtree([3,3,4,4,-1], ['a', 'b', 'c'])\n",
    "print(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': [1], '1': [0, 1], '2': [0, 0, 1], '3': [0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(xtree2code(code2xtree({'0':[1], '1':[0,1], '2':[0,0,1], '3':[0,0,0]})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your Shannon-Fano Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next section can only be completed once you have a working Shannon-Fano function `shannon_fano()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution: {'a': 0.07303050703931029, 'b': 0.04415788692917655, 'c': 0.06760701086735557, 'd': 0.0531896987507129, 'e': 0.07638640465681905, 'f': 0.07458877737764331, 'g': 0.07181276543870932, 'h': 0.10669415310046514, 'i': 0.1098461038297984, 'j': 0.0038473202881341793, 'k': 0.10841131710433789, 'l': 0.07775484976445701, 'm': 0.03569839729575642, 'n': 0.03852638150226022, 'o': 0.049562024552094075, 'p': 0.008886401502969677}\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shannon_fano' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-982dfa1cf1c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Probability distribution: {p}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshannon_fano\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Codebook: {c}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode2xtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shannon_fano' is not defined"
     ]
    }
   ],
   "source": [
    "#from vl_codes import shannon_fano\n",
    "from random import random\n",
    "p = [random() for k in range(16)]\n",
    "p = dict([(chr(k+ord('a')),p[k]/sum(p)) for k in range(len(p))])\n",
    "print(f'Probability distribution: {p}\\n')\n",
    "c = shannon_fano(p)\n",
    "print(f'Codebook: {c}\\n')\n",
    "xt = code2xtree(c)\n",
    "print(f'Cut and paste for phylo.io: {xtree2newick(xt)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can upload data from a file, for example `hamlet.txt`, and display the first few lines..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('hamlet.txt', 'r')\n",
    "hamlet = f.read()\n",
    "f.close()\n",
    "print(hamlet[:294])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute the startistics of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "frequencies = dict([(key, len(list(group))) for key, group in groupby(sorted(hamlet))])\n",
    "Nin = sum([frequencies[a] for a in frequencies])\n",
    "p = dict([(a,frequencies[a]/Nin) for a in frequencies])\n",
    "print(f'File length: {Nin}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the alphabet of symbols used in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(p))\n",
    "print(len(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to construct the Shannon-Fano code for this file, and view its tree (cut and paste into [phylo.io](https://phylo.io), don't forget to add a carriage return at the end, click on \"Branch Labels/Support\" under \"Settings\", then right-click on the root of the tree and select \"expand all\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = shannon_fano(p)\n",
    "print(len(c))\n",
    "xt = code2xtree(c)\n",
    "print(len(xt))\n",
    "print(xtree2newick(xt))\n",
    "print(len(c['&']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can actually encode the file `hamlet.txt` using the Shannon-Fano code we constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vl_codes import vl_encode\n",
    "hamlet_sf = vl_encode(hamlet, c)\n",
    "print(f'Length of binary sequence: {len(hamlet_sf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have commands to convert a bit sequence into a byte sequence (including a 3 bit prefix that helps us determine the length of the bit sequence):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vl_codes import bytes2bits, bits2bytes\n",
    "x = bits2bytes([0,1])\n",
    "print([format(a, '08b') for a in x])\n",
    "y = bytes2bits(x)\n",
    "print(f'The original bits are: {y}')\n",
    "print(bits2bytes([0,1,1,0,1,1,0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the bits to byte conversion to the compressed text of Hamlet to compute the length of the compressed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_zipped = bits2bytes(hamlet_sf)\n",
    "Nout = len(hamlet_zipped)\n",
    "print(f'Length of compressed string: {Nout}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compression ratio can be expressed in two ways, unitless or in bits/bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Compression ratio (rateless): {Nout/Nin}')\n",
    "print(f'Compression ratio (bits per byte): {8.0*Nout/Nin}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower bound for compression is the Entropy, measured in bits, that can be computed using an in-line function in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "H = lambda pr: -sum([pr[a]*log2(pr[a]) for a in pr])\n",
    "print(f'Entropy: {H(p)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to decode the compressed Hamlet sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vl_codes import vl_decode\n",
    "xt = code2xtree(c)\n",
    "hamlet_unzipped = vl_decode(hamlet_sf, xt)\n",
    "print(f'Length of unzipped file: {len(hamlet_unzipped)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the first few lines of the input (note the command `join` that turns the list of strings into one string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(''.join(hamlet_unzipped[:294]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing and uncompressing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we put it all together, compressing directly from input to output file. Play around with these commands once you implemented Huffman coding and arithmetic coding. We begin by importing the compression and decompression functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from camzip import camzip\n",
    "from camunzip import camunzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next commands define the method to be used and the filename. Modify those when you are trying other methods on various files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method = 'shannon_fano'\n",
    "filename = 'hamlet.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the actual compression and decompression..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camzip(method, filename)\n",
    "camunzip(filename + '.cz' + method[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few lines perform various statistical measurements and verifies that the decompressed file is identical to the compressed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filecmp import cmp\n",
    "from os import stat\n",
    "from json import load\n",
    "Nin = stat(filename).st_size\n",
    "print(f'Length of original file: {Nin} bytes')\n",
    "Nout = stat(filename + '.cz' + method[0]).st_size\n",
    "print(f'Length of compressed file: {Nout} bytes')\n",
    "print(f'Compression rate: {8.0*Nout/Nin} bits/byte')\n",
    "with open(filename + '.czp', 'r') as fp:\n",
    "    freq = load(fp)\n",
    "pf = dict([(a, freq[a]/Nin) for a in freq])\n",
    "print(f'Entropy: {H(pf)} bits per symbol')\n",
    "if cmp(filename,filename+'.cuz'):\n",
    "    print('The two files are the same')\n",
    "else:\n",
    "    print('The files are different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huffman coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will only work once you have a working function `huffman()`. We first repeat the tree construction and visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vl_codes import huffman\n",
    "xt = huffman(p)\n",
    "print(xtree2newick(xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtree2code(huffman({'a':.5, 'b':.25, 'c':.25, 'd':0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how the Huffman tree differs from the Shannon-Fano tree. What are its shortest and its longest codeword? You can use the `camzip` code above changing the method to `'huffman'` to test the compression rate etc. You may also want to do it by hand to test the error resilience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = xtree2code(xt)\n",
    "hamlet_huf = vl_encode(hamlet, c)\n",
    "hamlet_decoded = vl_decode(hamlet_huf, xt)\n",
    "print(''.join(hamlet_decoded[:294]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now introduce a random bit flip (bit 400 flipped) in the compressed sequence and observe the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_corrupted = hamlet_huf.copy()\n",
    "hamlet_corrupted[400] ^= 1\n",
    "hamlet_decoded = vl_decode(hamlet_corrupted, xt)\n",
    "print(''.join(hamlet_decoded[:297]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try \"by hand\" to operate the steps of arithmetic coding using floating point numbers. We first compute the cumulative probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = [0.0]\n",
    "for a in p:\n",
    "    f.append(f[-1]+p[a])\n",
    "f.pop()\n",
    "f = dict([(a,f[k]) for a,k in zip(p,range(len(p)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform by hand the first `n=4` steps of arithmetic coding. Vary `n` to observe the loss of precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, hi = 0.0, 1.0\n",
    "n = 4\n",
    "for k in range(n):\n",
    "    a = hamlet[k]\n",
    "    lohi_range = hi - lo\n",
    "    hi = lo + lohi_range * (f[a] + p[a])\n",
    "    lo = lo + lohi_range * f[a]\n",
    "print(f'lo = {lo}, hi = {hi}, hi-lo = {hi-lo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output sequence is roughly the binary expression of `lo` (not exactly) and we can compute and observe it. What length `ell` would we need when encoding all of Hamlet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil\n",
    "ell = ceil(-log2(hi-lo))+2 if hi-lo > 0.0 else 96\n",
    "print(bin(floor(lo*2**ell)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode and decode Hamlet again using arithmetic coding and verify that the first few lines of the play look as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arithmetic as arith\n",
    "arith_encoded = arith.encode(hamlet, p)\n",
    "arith_decoded = arith.decode(arith_encoded, p, Nin)\n",
    "print('\\n'+''.join(arith_decoded[:294]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now repeat the steps above but introduce a one bit mistake (bit 399 flipped) and observe the effect on the decoded text. Repeat this experiment varying the location of the mistake or adding more than one mistake. What do you observe? Can you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arith_corrupted = arith_encoded.copy()\n",
    "arith_corrupted[399] ^= 1\n",
    "arith_decoded = arith.decode(arith_corrupted, p, Nin)\n",
    "print('\\n'+''.join(arith_decoded[:294]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtree2newick(tree2xtree([-1,0,0,1,1,3,3,4,2]),[str(chr(a+ord('0'))) for a in range(9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
